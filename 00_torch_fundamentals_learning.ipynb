{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6720023f-bdc6-4b6b-bee9-8a728193ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1eb8ce0-dd9b-4d64-8b72-6e7922268697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan 25 21:06:14 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050 Ti     Off | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   40C    P8              N/A /  16W |    131MiB /  4096MiB |     15%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1360      G   /usr/lib/xorg/Xorg                           45MiB |\n",
      "|    0   N/A  N/A    113925      C   ...loy/anaconda3/envs/torch/bin/python       82MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b176b4d3-e852-4b3f-b6f4-f88ede1693c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed on the GPU\n",
    "torch.cuda.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff831f8e-555a-4537-a06c-f84dcfd2acdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0290, 0.4019, 0.2598],\n",
       "         [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n",
       " tensor([[0.0518, 0.4681, 0.6738],\n",
       "         [0.3315, 0.7837, 0.5631]], device='cuda:0'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Check for access to GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")\n",
    "# Create two random tensors on GPU\n",
    "tensor_gpu_A = torch.rand(2,3).to(device)\n",
    "tensor_gpu_B = torch.rand(2,3).to(device)\n",
    "\n",
    "tensor_gpu_A, tensor_gpu_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9eb0eb42-f5ec-4b56-bc89-0e83f4d3f767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3647, 0.4709],\n",
       "         [0.5184, 0.5617]], device='cuda:0'),\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform matmul on tensor_A and tensor_B\n",
    "result = torch.matmul(tensor_gpu_A, tensor_gpu_B.T)\n",
    "result, result.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2cd6333-27cc-41b1-ad10-097704da85f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max: 0.5617256760597229\n",
      "Min: 0.3647301495075226\n"
     ]
    }
   ],
   "source": [
    "# Find max\n",
    "print(f\"Max: {result.max()}\")\n",
    "# Find min\n",
    "print(f\"Min: {result.min()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6a4f0e3-c18a-498d-9b83-62810f147e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3, device='cuda:0'), tensor(0, device='cuda:0'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find arg max\n",
    "max_index = torch.argmax(result)\n",
    "\n",
    "# Find arg min\n",
    "min_index = torch.argmin(result)\n",
    "\n",
    "max_index, min_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21116a68-fcd4-4665-b550-5d3f3f5eb179",
   "metadata": {},
   "source": [
    "10. Make a random tensor with shape (1, 1, 1, 10) and then create a new tensor with all the 1 dimensions removed to be left with a tensor of shape (10). Set the seed to 7 when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape.\n",
    "The output should look like:\n",
    "\n",
    "```\n",
    "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
    "           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\n",
    "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
    "        0.8513]) torch.Size([10])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ec02bd7-79b6-4bc8-a5ea-415fa6ca076a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
      "           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\n",
      "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
      "        0.8513]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "torch.manual_seed(7)\n",
    "\n",
    "# Create random tensor\n",
    "random_A = torch.rand(1,1,1,10)\n",
    "\n",
    "# Remove single dimensions\n",
    "random_B = random_A.squeeze()\n",
    "\n",
    "# Print out tensors and their shapes\n",
    "print(random_A, random_A.shape)\n",
    "print(random_B, random_B.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
