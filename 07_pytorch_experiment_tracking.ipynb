{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cd4b84d-5753-44ce-8e63-5492bac65258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(f\"[INFO] Couldn't find the torchinfo...\\n Installing it.....\")\n",
    "    !pip install -qq torchinfo\n",
    "    from torchinfo import summary\n",
    "\n",
    "# Try to import going_moduler directory. download it from GitHub, if it doesn't work\n",
    "try:\n",
    "    from going_modular import data_setup, engine, utils\n",
    "except:\n",
    "    print(f\"[INFO] Couldn't find the directory...\\n Downloading it from github.....\")\n",
    "    !git clone https://github.com/Niloy009/learning_pytorch.git\n",
    "    !mv leaning_pytorch/going_modular\n",
    "    !rm -rf learning_pytorch\n",
    "    from going_modular import data_setup, engine, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83cd8261-5849-4bac-8388-d0f1c786a2ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03d242bf-319c-4131-9b2d-43f165560c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed\n",
    "def set_seeds(seed: int=42):\n",
    "    \"\"\"Sets random sets for torch operations.\n",
    "\n",
    "    Args:\n",
    "        seed (int, optional): Random seed to set. Defaults to 42.\n",
    "    \"\"\"\n",
    "\n",
    "    # set the seed for the general torch operation\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e48713-36df-41bf-91a2-87d36eee34dc",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "162227cc-9d6c-49fc-ae80-9c4e5f2e1476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "def download_data(source: str, \n",
    "                  destination: str, \n",
    "                  remove_source: bool = True) -> Path:\n",
    "    \"\"\"Download a ziiped dataset from source and unzip to destination\n",
    "\n",
    "    Args:\n",
    "        source: The source path where the data will download from.\n",
    "        destination: The destination path where the data will download and unzip to.\n",
    "        remove_source: Whether the source remove or not after download.\n",
    "        \n",
    "    Returns:\n",
    "        pathlib.Path to downloaded data.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Setup data path\n",
    "    data_path = Path(\"data/\")\n",
    "    image_path = data_path / destination # images from a subset of classes from the Food101 dataset\n",
    "\n",
    "    # If the image folder doesn't exist, download it and prepare it...\n",
    "    if image_path.is_dir():\n",
    "      print(f\"[INFO] {image_path} directory exists, skipping re-download.\")\n",
    "    else:\n",
    "      print(f\"[INFO] Did not find {image_path}, downloading it...\")\n",
    "      image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "      # Download pizza, steak, sushi data\n",
    "      target_file = Path(source).name\n",
    "      with open(data_path / target_file, \"wb\") as f:\n",
    "        request = requests.get(source)\n",
    "        print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
    "        f.write(request.content)\n",
    "  \n",
    "      # unzip pizza, steak, sushi data\n",
    "      with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
    "        print(f\"[INFO] Unzipping {target_file}...\")\n",
    "        zip_ref.extractall(image_path)\n",
    "  \n",
    "      # Remove .zip file\n",
    "      if remove_source:\n",
    "          os.remove(data_path / target_file)\n",
    "\n",
    "    return image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "187caa4f-62c0-4f48-bc0c-3c8928b1face",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data/pizza_steak_sushi directory exists, skipping re-download.\n"
     ]
    }
   ],
   "source": [
    "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\", \n",
    "              destination=\"pizza_steak_sushi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7876c76-e040-4ca7-8e19-ef28ceac04c7",
   "metadata": {},
   "source": [
    "# Manual Transform and create dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef3b3a57-8f42-4f4c-89e5-1a3ed3d39d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('data/pizza_steak_sushi/train'),\n",
       " PosixPath('data/pizza_steak_sushi/test'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup directories\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ecb938-3cf6-4ce6-bc06-f533a422f1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Manually created transforms: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f0a42980b30>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f0b54bad760>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup ImageNet normalization levels (turns all images into similar distribution as ImageNet)\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Create transform pipeline manually\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])           \n",
    "print(f\"[INFO] Manually created transforms: {manual_transforms}\")\n",
    "\n",
    "train_dataloader_manual, test_dataloaler_manual, class_names = data_setup.create_dataloaders(train_dir=train_dir, \n",
    "                                                                                test_dir=test_dir, \n",
    "                                                                                transform=manual_transforms, \n",
    "                                                                                batch_size=32)\n",
    "train_dataloader_manual, test_dataloaler_manual, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45921ff-05e6-46a4-a51f-1f4316bc61b9",
   "metadata": {},
   "source": [
    "# Automate Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8a25cf6-6f2b-4c93-97ba-f25799b44c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Automatically created transforms: ImageClassification(\n",
      "    crop_size=[224]\n",
      "    resize_size=[256]\n",
      "    mean=[0.485, 0.456, 0.406]\n",
      "    std=[0.229, 0.224, 0.225]\n",
      "    interpolation=InterpolationMode.BICUBIC\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f0a42980230>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f0a42980cb0>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup pretrained weights (plenty of these available in torchvision.models)\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "# Get transforms from weights (these are the transforms that were used to obtain the weights)\n",
    "automatic_transforms = weights.transforms() \n",
    "print(f\"[INFO] Automatically created transforms: {automatic_transforms}\")\n",
    "\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir=train_dir, \n",
    "                                                                                test_dir=test_dir, \n",
    "                                                                                transform=automatic_transforms, \n",
    "                                                                                batch_size=32)\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6494d80d-1053-4561-aa5c-6b99523f984a",
   "metadata": {},
   "source": [
    "# Get Pretrained Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2319db12-a4c7-4ba9-b064-1a6817ee80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the weights of pretrained model Efficientnet_B0\n",
    "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
    "\n",
    "# Set up the model with weights and send it to the device\n",
    "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
    "\n",
    "# View the model\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ac53c4-d105-4765-9f39-5645b3acf349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all base layers by setting attribute required_grad to False\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Since we're creating a new layer with random weights (torch.nn.Linear), \n",
    "# let's set the seeds\n",
    "set_seeds()\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280, out_features=len(class_names), bias=True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b70dcd-c13a-470b-8125-4778024158b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape        Output Shape       Param #            Trainable\n",
       "====================================================================================================================================\n",
       "EfficientNet (EfficientNet)                                  [32, 3, 224, 224]  [32, 3]            --                 Partial\n",
       "├─Sequential (features)                                      [32, 3, 224, 224]  [32, 1280, 7, 7]   --                 False\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 224, 224]  [32, 32, 112, 112] --                 False\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 224, 224]  [32, 32, 112, 112] (864)              False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 32, 112, 112] [32, 32, 112, 112] (64)               False\n",
       "│    │    └─SiLU (2)                                         [32, 32, 112, 112] [32, 32, 112, 112] --                 --\n",
       "│    └─Sequential (1)                                        [32, 32, 112, 112] [32, 16, 112, 112] --                 False\n",
       "│    │    └─MBConv (0)                                       [32, 32, 112, 112] [32, 16, 112, 112] (1,448)            False\n",
       "│    └─Sequential (2)                                        [32, 16, 112, 112] [32, 24, 56, 56]   --                 False\n",
       "│    │    └─MBConv (0)                                       [32, 16, 112, 112] [32, 24, 56, 56]   (6,004)            False\n",
       "│    │    └─MBConv (1)                                       [32, 24, 56, 56]   [32, 24, 56, 56]   (10,710)           False\n",
       "│    └─Sequential (3)                                        [32, 24, 56, 56]   [32, 40, 28, 28]   --                 False\n",
       "│    │    └─MBConv (0)                                       [32, 24, 56, 56]   [32, 40, 28, 28]   (15,350)           False\n",
       "│    │    └─MBConv (1)                                       [32, 40, 28, 28]   [32, 40, 28, 28]   (31,290)           False\n",
       "│    └─Sequential (4)                                        [32, 40, 28, 28]   [32, 80, 14, 14]   --                 False\n",
       "│    │    └─MBConv (0)                                       [32, 40, 28, 28]   [32, 80, 14, 14]   (37,130)           False\n",
       "│    │    └─MBConv (1)                                       [32, 80, 14, 14]   [32, 80, 14, 14]   (102,900)          False\n",
       "│    │    └─MBConv (2)                                       [32, 80, 14, 14]   [32, 80, 14, 14]   (102,900)          False\n",
       "│    └─Sequential (5)                                        [32, 80, 14, 14]   [32, 112, 14, 14]  --                 False\n",
       "│    │    └─MBConv (0)                                       [32, 80, 14, 14]   [32, 112, 14, 14]  (126,004)          False\n",
       "│    │    └─MBConv (1)                                       [32, 112, 14, 14]  [32, 112, 14, 14]  (208,572)          False\n",
       "│    │    └─MBConv (2)                                       [32, 112, 14, 14]  [32, 112, 14, 14]  (208,572)          False\n",
       "│    └─Sequential (6)                                        [32, 112, 14, 14]  [32, 192, 7, 7]    --                 False\n",
       "│    │    └─MBConv (0)                                       [32, 112, 14, 14]  [32, 192, 7, 7]    (262,492)          False\n",
       "│    │    └─MBConv (1)                                       [32, 192, 7, 7]    [32, 192, 7, 7]    (587,952)          False\n",
       "│    │    └─MBConv (2)                                       [32, 192, 7, 7]    [32, 192, 7, 7]    (587,952)          False\n",
       "│    │    └─MBConv (3)                                       [32, 192, 7, 7]    [32, 192, 7, 7]    (587,952)          False\n",
       "│    └─Sequential (7)                                        [32, 192, 7, 7]    [32, 320, 7, 7]    --                 False\n",
       "│    │    └─MBConv (0)                                       [32, 192, 7, 7]    [32, 320, 7, 7]    (717,232)          False\n",
       "│    └─Conv2dNormActivation (8)                              [32, 320, 7, 7]    [32, 1280, 7, 7]   --                 False\n",
       "│    │    └─Conv2d (0)                                       [32, 320, 7, 7]    [32, 1280, 7, 7]   (409,600)          False\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1280, 7, 7]   [32, 1280, 7, 7]   (2,560)            False\n",
       "│    │    └─SiLU (2)                                         [32, 1280, 7, 7]   [32, 1280, 7, 7]   --                 --\n",
       "├─AdaptiveAvgPool2d (avgpool)                                [32, 1280, 7, 7]   [32, 1280, 1, 1]   --                 --\n",
       "├─Sequential (classifier)                                    [32, 1280]         [32, 3]            --                 True\n",
       "│    └─Dropout (0)                                           [32, 1280]         [32, 1280]         --                 --\n",
       "│    └─Linear (1)                                            [32, 1280]         [32, 3]            3,843              True\n",
       "====================================================================================================================================\n",
       "Total params: 4,011,391\n",
       "Trainable params: 3,843\n",
       "Non-trainable params: 4,007,548\n",
       "Total mult-adds (Units.GIGABYTES): 12.31\n",
       "====================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3452.09\n",
       "Params size (MB): 16.05\n",
       "Estimated Total Size (MB): 3487.41\n",
       "===================================================================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "# Get a summary of the model\n",
    "summary(model=model, \n",
    "        input_size=(32,3,224,224), \n",
    "        verbose=0, \n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable'], \n",
    "        col_width=18, row_settings=['var_names'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b294293-f611-4079-99e6-9940d35a5f60",
   "metadata": {},
   "source": [
    "# Train a single model and track it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27dcda7a-723a-4c01-b0ab-cba1bbcacf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "accuracy = Accuracy(task='multiclass', num_classes=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eae49f35-bb3b-4c10-a389-fb71e8abbe93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.tensorboard.writer.SummaryWriter at 0x7f0a4275c2c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Summary writer\n",
    "try:\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "except:\n",
    "    print(f'[INFO]: Could not find tensorboard..... installing it!! ')\n",
    "    !pip install -qq tensorboard\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    \n",
    "\n",
    "writer = SummaryWriter()\n",
    "writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca8354ab-3d05-49fe-8ce5-218ba4c4a6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from going_modular.engine import train_step, test_step\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          loss_fn: torch.nn.Module, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          accuracy: torchmetrics.classification.accuracy.Accuracy,\n",
    "          epochs: int,\n",
    "          device: torch.device) -> Dict[str, List]:\n",
    "    \"\"\"Trains and test a PyTorch model\n",
    "\n",
    "    Passes a target PyTorch model through train_step() and test_step()\n",
    "    functions for a number of epochs. training and testing the model in the same epoch loop.\n",
    "\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "\n",
    "    Args:\n",
    "        model: A PyTorch model to be tested.\n",
    "        train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "        test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "        loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "        accuracy: A torchmetric module to calculate accuracy.\n",
    "        epochs: An integar indicating how many epochs to train for.\n",
    "        device: A target device to compute on (i.e. \"cuda\" or \"cpu\")\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of training and testing loss as well as training and\n",
    "        testing accuracy metrics. Each metric has a value in a list for \n",
    "        each epoch.\n",
    "        In the form: {train_loss: [...],\n",
    "                      train_acc: [...],\n",
    "                      test_loss: [...],\n",
    "                      test_acc: [...]} \n",
    "        For example if training for epochs=2: \n",
    "                     {train_loss: [2.0616, 1.0537],\n",
    "                      train_acc: [0.3945, 0.3945],\n",
    "                      test_loss: [1.2641, 1.5706],\n",
    "                      test_acc: [0.3400, 0.2973]} \n",
    "  \"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = { \"train_loss\": [], \n",
    "                \"train_accuracy\": [], \n",
    "                \"test_loss\": [], \n",
    "                \"test_accuracy\": []\n",
    "              }\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_accuracy = train_step(model=model, \n",
    "                                                dataloader=train_dataloader, \n",
    "                                                loss_fn=loss_fn, \n",
    "                                                optimizer=optimizer, \n",
    "                                                accuracy=accuracy, \n",
    "                                                device=device)\n",
    "        test_loss, test_accuracy = test_step(model=model, \n",
    "                                             dataloader=test_dataloader, \n",
    "                                             loss_fn=loss_fn,\n",
    "                                             accuracy=accuracy, \n",
    "                                             device=device)\n",
    "        \n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss: .4f} | \"\n",
    "            f\"train_accuracy: {train_accuracy: .4f} | \"\n",
    "            f\"test_loss: {test_loss: .4f} | \"\n",
    "            f\"test_accuracy: {test_accuracy: .4f}\"\n",
    "        )\n",
    "        # 5. update the results\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_accuracy\"].append(train_accuracy)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_accuracy\"].append(test_accuracy)\n",
    "\n",
    "        #### New: Experiment tracking with tensorboard ####\n",
    "        writer.add_scalars(main_tag=\"Loss\", \n",
    "                           tag_scalar_dict={\"train_loss\": train_loss, \n",
    "                                            \"test_loss\": test_loss}, \n",
    "                           global_step=epoch)\n",
    "        \n",
    "        writer.add_scalars(main_tag=\"Accuracy\", \n",
    "                           tag_scalar_dict={\"train_accuracy\": train_accuracy, \n",
    "                                            \"test_accuracy\": test_accuracy}, \n",
    "                           global_step=epoch)\n",
    "\n",
    "        writer.add_graph(model=model, input_to_model=torch.randn(32,3,224,224).to(device))\n",
    "\n",
    "        # Close the writer\n",
    "        writer.close()\n",
    "\n",
    "        #### End: Experiment tracking with tensorboard ####\n",
    "        \n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c2158f7-0686-40af-b9d6-1f90ad2531ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ee9f05447a4f8ca8bfbdf8b22176c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss:  1.0948 | train_accuracy:  0.3984 | test_loss:  0.9034 | test_accuracy:  0.6411\n",
      "Epoch: 2 | train_loss:  0.9005 | train_accuracy:  0.6445 | test_loss:  0.7874 | test_accuracy:  0.8561\n",
      "Epoch: 3 | train_loss:  0.8115 | train_accuracy:  0.7500 | test_loss:  0.6749 | test_accuracy:  0.8759\n",
      "Epoch: 4 | train_loss:  0.6853 | train_accuracy:  0.7383 | test_loss:  0.6704 | test_accuracy:  0.8352\n",
      "Epoch: 5 | train_loss:  0.7091 | train_accuracy:  0.7383 | test_loss:  0.6768 | test_accuracy:  0.8040\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "# Note: Not using engine.train() as we modified the function above\n",
    "\n",
    "set_seeds()\n",
    "results = train(model=model, \n",
    "                train_dataloader=train_dataloader, \n",
    "                test_dataloader=test_dataloader, \n",
    "                loss_fn=loss_fn, \n",
    "                optimizer=optimizer,\n",
    "                accuracy=accuracy, \n",
    "                epochs=5, \n",
    "                device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22880a7d-ac59-4f07-af83-1e2f6fcfd57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets view our experiment\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78eecf0-0de2-4623-93f2-a8e86df47d47",
   "metadata": {},
   "source": [
    "# Create a function to prepare a `SummaryWriter()` instance\n",
    "\n",
    "By default our `SummaryWriter()` class aves to `log_dir`.\n",
    "\n",
    "How about if we wanted to save different experiments to different folders?\n",
    "\n",
    "in simple word **one experiment = one folder**\n",
    "\n",
    "For example, we'd like to track:\n",
    "\n",
    "* Experiment data/timestamp\n",
    "* Experiment name\n",
    "* Model name\n",
    "* Extra - is there anything else that should be tracked?\n",
    "\n",
    "Let's create a function to create a `SummaryWriter()` instance to take all of these things into account.\n",
    "\n",
    "So ideally we end up tracking experiment to a directory:\n",
    "\n",
    "`runs/YYYY-MM-DD/experiment_name/model_name/extra`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d7b6f15-60f8-4d87-ad57-d961675f5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def create_writer(experiment_name: str, model_name: str, extra: str = None) -> torch.utils.tensorboard.writer.SummaryWriter():\n",
    "    \"\"\"Create a torch.utils.tensorboard.writer.SummaryWriter() instance saving to a specific log_dir\n",
    "    \n",
    "    log_dir is a combination of runs/timestamp/experiment_name/model_name/extra\n",
    "\n",
    "    Where timestamp is current date in YYYY-MM-DD format\n",
    "\n",
    "    Args:\n",
    "        experiment_name (str): Name of the experiment.\n",
    "        model_name (str): Name of the model\n",
    "        extra (str, optional): Anything extra to add to the directory.\n",
    "\n",
    "    Returns:\n",
    "        torch.utils.tensorboard.writer.SummaryWriter(): Instance of a writer saving to the specific log_dir.\n",
    "\n",
    "    Example usage:\n",
    "        # Create a writer saving to \"runs/2025-Apr-05/data_10_percent/effnetb2/5_epochs/\"\n",
    "        writer = create_writer(experiment_name=\"data_10_percent\",\n",
    "                               model_name=\"effnetb2\",\n",
    "                               extra=\"5_epochs\")\n",
    "        # The above is the same as:\n",
    "        writer = SummaryWriter(log_dir=\"runs/2022-06-04/data_10_percent/effnetb2/5_epochs/\")\n",
    "    \"\"\"\n",
    "\n",
    "    # Get timestamp of current date in reverse order (YYYY-MM-DD)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%b-%d\")\n",
    "\n",
    "    if extra:\n",
    "        # create log directory path\n",
    "        log_dir = os.path.join('runs', timestamp, experiment_name, model_name, extra)\n",
    "    else:\n",
    "        log_dir = os.path.join('runs', timestamp, experiment_name, model_name)\n",
    "\n",
    "    print(f\"[INFO] Created SummaryWriter saving to {log_dir}\")\n",
    "    return SummaryWriter(log_dir=log_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f81eb63-3d2a-4608-b622-4587d3d5b0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter saving to runs/2025-Apr-05/data_10_percent/efficientnetb0/5_epochs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.tensorboard.writer.SummaryWriter at 0x7f0a2041c800>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_writer = create_writer(experiment_name='data_10_percent', model_name=\"efficientnetb0\", extra='5_epochs')\n",
    "example_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27566e55-b222-4d22-896b-0d8356b6627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "from going_modular.engine import train_step, test_step\n",
    "\n",
    "\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          loss_fn: torch.nn.Module, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          accuracy: torchmetrics.classification.accuracy.Accuracy,\n",
    "          epochs: int,\n",
    "          device: torch.device, \n",
    "          writer: torch.utils.tensorboard.writer.SummaryWriter) -> Dict[str, List]:\n",
    "    \"\"\"Trains and test a PyTorch model\n",
    "\n",
    "    Passes a target PyTorch model through train_step() and test_step()\n",
    "    functions for a number of epochs. training and testing the model in the same epoch loop.\n",
    "\n",
    "    Calculates, prints and stores evaluation metrics throughout.\n",
    "    \n",
    "    Stores metrics to specified writer log_dir if present.\n",
    "    \n",
    "    Args:\n",
    "        model: A PyTorch model to be tested.\n",
    "        train_dataloader: A DataLoader instance for the model to be trained on.\n",
    "        test_dataloader: A DataLoader instance for the model to be tested on.\n",
    "        loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
    "        optimizer: A PyTorch optimizer to help minimize the loss function.\n",
    "        accuracy: A torchmetric module to calculate accuracy.\n",
    "        epochs: An integar indicating how many epochs to train for.\n",
    "        device: A target device to compute on (i.e. \"cuda\" or \"cpu\").\n",
    "        writer: A SummaryWriter() instance to log model results to.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        A dictionary of training and testing loss as well as training and\n",
    "        testing accuracy metrics. Each metric has a value in a list for \n",
    "        each epoch.\n",
    "        In the form: {train_loss: [...],\n",
    "                      train_acc: [...],\n",
    "                      test_loss: [...],\n",
    "                      test_acc: [...]} \n",
    "        For example if training for epochs=2: \n",
    "                     {train_loss: [2.0616, 1.0537],\n",
    "                      train_acc: [0.3945, 0.3945],\n",
    "                      test_loss: [1.2641, 1.5706],\n",
    "                      test_acc: [0.3400, 0.2973]} \n",
    "  \"\"\"\n",
    "    # Create empty results dictionary\n",
    "    results = { \"train_loss\": [], \n",
    "                \"train_accuracy\": [], \n",
    "                \"test_loss\": [], \n",
    "                \"test_accuracy\": []\n",
    "              }\n",
    "\n",
    "    # Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_accuracy = train_step(model=model, \n",
    "                                                dataloader=train_dataloader, \n",
    "                                                loss_fn=loss_fn, \n",
    "                                                optimizer=optimizer, \n",
    "                                                accuracy=accuracy, \n",
    "                                                device=device)\n",
    "        test_loss, test_accuracy = test_step(model=model, \n",
    "                                             dataloader=test_dataloader, \n",
    "                                             loss_fn=loss_fn,\n",
    "                                             accuracy=accuracy, \n",
    "                                             device=device)\n",
    "        \n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss: .4f} | \"\n",
    "            f\"train_accuracy: {train_accuracy: .4f} | \"\n",
    "            f\"test_loss: {test_loss: .4f} | \"\n",
    "            f\"test_accuracy: {test_accuracy: .4f}\"\n",
    "        )\n",
    "        # 5. update the results\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_accuracy\"].append(train_accuracy)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_accuracy\"].append(test_accuracy)\n",
    "\n",
    "        #### New: Experiment tracking with tensorboard ####\n",
    "        if writer:\n",
    "            writer.add_scalars(main_tag=\"Loss\", \n",
    "                               tag_scalar_dict={\"train_loss\": train_loss, \n",
    "                                                \"test_loss\": test_loss}, \n",
    "                               global_step=epoch)\n",
    "            \n",
    "            writer.add_scalars(main_tag=\"Accuracy\", \n",
    "                               tag_scalar_dict={\"train_accuracy\": train_accuracy, \n",
    "                                                \"test_accuracy\": test_accuracy}, \n",
    "                               global_step=epoch)\n",
    "    \n",
    "            writer.add_graph(model=model, input_to_model=torch.randn(32,3,224,224).to(device))\n",
    "    \n",
    "            # Close the writer\n",
    "            writer.close()\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        #### End: Experiment tracking with tensorboard ####\n",
    "        \n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2415068d-dba5-4bc8-af8b-e11834e2496f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b59c81-165c-41f7-8fe9-37f15b5c9761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d4bb9-1958-4e4a-a595-aca48ca66669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf49697-0517-4753-bcf3-e969fcb927e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
